* [#A] Deep Dive Into Redis                                         :Project:
#+STARTUP: showeverything
#+OPTIONS: toc:nil \n:t ^:nil creator:nil d:nil
#+EXPORT_EXCLUDE_TAGS: exclude noexport BLOG
:PROPERTIES:
:type: systemdesign, designproject
:END:
---------------------------------------------------------------------
Deep Dive Into Redis
---------------------------------------------------------------------
#+BEGIN_HTML
<a href="https://github.com/dennyzhang/architect.dennyzhang.com/tree/master/design-project/design-redis"><img align="right" width="200" height="183" src="https://www.dennyzhang.com/wp-content/uploads/denny/watermark/github.png" /></a>
#+END_HTML

Similar Posts:
- [[https://architect.dennyzhang.com/design-concept][Concepts For System Design]]
- Tag: [[https://architect.dennyzhang.com/tag/systemdesign][#systemdesign]]
---------------------------------------------------------------------

[[https://architect.dennyzhang.com/explain-cache][Design: How Does Caching Work]]

---------------------------------------------------------------------
| Name            | Summary                                                                             |
|-----------------+-------------------------------------------------------------------------------------|
| Data persistent | All data is eventually persistent. But can also be immediately                      |
| Availability    | Redis has built-in master/slave replication. Slave can be promoted to master on fly |
| Atomic          | Support for atomic operations                                                       |
| Reference       | [[https://www.slideshare.net/dvirsky/introduction-to-redis][SlideShare: What is redis]]                                                           |

---------------------------------------------------------------------
Q: What are Redis' typical use cases?

All data is in memory but also persists. Mostly operations are O(1) behavior.

Redis is a single threaded application uses async IO. This helps to achieve high throughput.

Redis Key features:
| Name         | Summary                         |
|--------------+---------------------------------|
| Get/Set/Incr |                                 |
| Lists        |                                 |
| Sets         |                                 |
| Sorted Sets  |                                 |
| Hash Tables  |                                 |
| PubSub       |                                 |
| SORT         |                                 |
| Transactions | Support for atomic transactions |
---------------------------------------------------------------------

[[https://redis.io/topics/lru-cache][Link: Using Redis as an LRU cache]]: 
| Eviction Policy | Description                                                                           |
|-----------------+---------------------------------------------------------------------------------------|
| allkeys-lru     | The cache evicts the least recently used (LRU) keys regardless of TTL set.            |
| allkeys-lfu     | The cache evicts the least frequently used (LFU) keys regardless of TTL set.          |
| volatile-lru    | The cache evicts the least recently used (LRU) keys from those that have a TTL set.   |
| volatile-lfu    | The cache evicts the least frequently used (LFU) keys from those that have a TTL set. |
| volatile-ttl    | The cache evicts the keys with the shortest TTL set.                                  |
| volatile-random | The cache randomly evicts keys with a TTL set.                                        |
| allkeys-random  | The cache randomly evicts keys regardless of TTL set.                                 |
| no-eviction     | The cache doesn't evict keys at all. This blocks future writes until memory frees up  |

In general as a rule of thumb:

- Use the allkeys-lru policy when you expect a power-law distribution in the popularity of your requests, that is, you expect that a subset of elements will be accessed far more often than the rest. This is a good pick if you are unsure.
- Use the allkeys-random if you have a cyclic access where all the keys are scanned continuously, or when you expect the distribution to be uniform (all elements likely accessed with the same probability).
- Use the volatile-ttl if you want to be able to provide hints to Redis about what are good candidate for expiration by using different TTL values when you create your cache objects.

Generally, least recently used (LRU)-based policies are more common for basic caching use cases. Also, if you are experiencing evictions with your cluster, it is usually a sign that you should scale up or scale out to accommodate the additional data. 

---------------------------------------------------------------------
Q: How cache evictions works in Redis?

A: [[https://redis.io/topics/lru-cache][link]]
---------------------------------------------------------------------
Q: how redis support distributed locks?

A: 
---------------------------------------------------------------------
Q: how redis supports transactions?

A: 
---------------------------------------------------------------------
Q: how redis supports zset data type?

A: [[https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-2-what-redis-data-structures-look-like/1-2-5-sorted-sets-in-redis/][link]]
---------------------------------------------------------------------
Q: how redis do the data partitioning?

A: 
---------------------------------------------------------------------
Q: how redis support high-throughput counter?

A: 
---------------------------------------------------------------------
Q: What are the use cases for redis Pub/Sub functionality?

A:
---------------------------------------------------------------------
* org-mode configuration                                           :noexport:
#+STARTUP: overview customtime noalign logdone showall
#+DESCRIPTION:
#+KEYWORDS:
#+LATEX_HEADER: \usepackage[margin=0.6in]{geometry}
#+LaTeX_CLASS_OPTIONS: [8pt]
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage{lastpage}
#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \pagestyle{fancy}
#+LATEX_HEADER: \fancyhf{}
#+LATEX_HEADER: \rhead{Updated: \today}
#+LATEX_HEADER: \rfoot{\thepage\ of \pageref{LastPage}}
#+LATEX_HEADER: \lfoot{\href{https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-featuredesign-A4}{GitHub: https://github.com/dennyzhang/cheatsheet.dennyzhang.com/tree/master/cheatsheet-featuredesign-A4}}
#+LATEX_HEADER: \lhead{\href{https://cheatsheet.dennyzhang.com/cheatsheet-slack-A4}{Blog URL: https://cheatsheet.dennyzhang.com/cheatsheet-featuredesign-A4}}
#+AUTHOR: Denny Zhang
#+EMAIL:  denny@dennyzhang.com
#+TAGS: noexport(n)
#+PRIORITIES: A D C
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_EXCLUDE_TAGS: exclude noexport
#+SEQ_TODO: TODO HALF ASSIGN | DONE BYPASS DELEGATE CANCELED DEFERRED
#+LINK_UP:
#+LINK_HOME:
* redis zset                                                       :noexport:
https://zsr.github.io/2017/07/03/redis-zset%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0/

skiplist为了避免这一问题,它不要求上下相邻两层链表之间的节点个数有严格的对应关系,而是为每个节点随机出一个层数(level).
